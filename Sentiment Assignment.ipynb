{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS 509 Sentiment Assignment\n",
    "\n",
    "This notebook holds the Sentiment Assignment for Module 6 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In a previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we apply sentiment analysis to those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet,opinion_lexicon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import advertools as adv\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"/Users/colebailey/Documents/USD/TextMining/Mod6/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\"\n",
    "\n",
    "positive_words_file = \"/Users/colebailey/Documents/USD/TextMining/Mod6/positive-words.txt\"\n",
    "negative_words_file = \"/Users/colebailey/Documents/USD/TextMining/Mod6/negative-words.txt\"\n",
    "tidy_text_file = \"/Users/colebailey/Documents/USD/TextMining/Mod6/tidytext_sentiments.txt\"\n",
    "\n",
    "artist_files = {'cher':'cher_follower_data.txt',\n",
    "                'robyn':'robynkonichiwa_follower_data.txt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A Pandas data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Come And Stay With Me\"\\n</td>\n",
       "      <td>\\n \\n \\n I'll send away all my false pride\\n A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Pirate\"\\n</td>\n",
       "      <td>\\n \\n \\n He'll sail on with the summer wind\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Stars\"\\n</td>\n",
       "      <td>\\n \\n \\n I was never one for saying what I rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"These Days\"\\n</td>\n",
       "      <td>\\n \\n \\n Well I've been out walking \\n And I d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Love So High\"\\n</td>\n",
       "      <td>\\n \\n \\n Every morning I would wake up\\n And I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                  song_name  \\\n",
       "0   cher  \"Come And Stay With Me\"\\n   \n",
       "1   cher                 \"Pirate\"\\n   \n",
       "2   cher                  \"Stars\"\\n   \n",
       "3   cher             \"These Days\"\\n   \n",
       "4   cher           \"Love So High\"\\n   \n",
       "\n",
       "                                                text  \n",
       "0  \\n \\n \\n I'll send away all my false pride\\n A...  \n",
       "1  \\n \\n \\n He'll sail on with the summer wind\\n ...  \n",
       "2  \\n \\n \\n I was never one for saying what I rea...  \n",
       "3  \\n \\n \\n Well I've been out walking \\n And I d...  \n",
       "4  \\n \\n \\n Every morning I would wake up\\n And I...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the lyrics data\n",
    "lyrics_path = data_location+lyrics_folder\n",
    "artists = ['cher','robyn']\n",
    "\n",
    "song_artist = []\n",
    "song_names = []\n",
    "song_lyrics = []\n",
    "\n",
    "for artist in artists:\n",
    "    \n",
    "    artist_path = lyrics_path + artist\n",
    "    songs = os.listdir(artist_path)\n",
    "\n",
    "    # get each song for our artist, read it in as a string, and append it to a list.\n",
    "    for song in songs:\n",
    "        song_path = artist_path + '/' + song\n",
    "        \n",
    "        with open(song_path) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # we also need a meaningful way to extract the song name. the rule for \n",
    "        # this dataset is that the title is separated by at least one carriage return,\n",
    "        # and we also know that it's always on the first line.\n",
    "        \n",
    "        this_song = lines[0]\n",
    "        this_lyrics = ' '.join(lines[1:])\n",
    "        \n",
    "        song_artist.append(artist)\n",
    "        song_names.append(this_song)\n",
    "        song_lyrics.append(this_lyrics)\n",
    "\n",
    "d = {\n",
    "        'artist':song_artist,\n",
    "        'song_name': song_names,\n",
    "        'text': song_lyrics\n",
    "    }\n",
    "\n",
    "#turn into a datafreame and do a sanity check\n",
    "lyrics_data = pd.DataFrame(d)\n",
    "lyrics_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the twitter data\n",
    "twitter_data = pd.read_csv(data_location + twitter_folder + artist_files['cher'],\n",
    "                           sep=\"\\t\",\n",
    "                           quoting=3)\n",
    "\n",
    "twitter_data['artist'] = \"cher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_2 = pd.read_csv(data_location + twitter_folder + artist_files['robyn'],\n",
    "                             sep=\"\\t\",\n",
    "                             quoting=3)\n",
    "twitter_data_2['artist'] = \"robyn\"\n",
    "\n",
    "twitter_data = pd.concat([\n",
    "    twitter_data,twitter_data_2])\n",
    "\n",
    "del(twitter_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the positive and negative words and the\n",
    "# tidytext sentiment. Store these so that the positive\n",
    "# words are associated with a score of +1 and negative words\n",
    "# are associated with a score of -1. You can use a dataframe or a \n",
    "# dictionary for this.\n",
    "\n",
    "positive = pd.read_csv(positive_words_file, skiprows = 35, header = None,encoding='latin-1')\n",
    "positive['sentiment'] = 1\n",
    "negative = pd.read_csv(negative_words_file, skiprows = 35, header = None, encoding='latin-1')\n",
    "negative['sentiment'] = -1\n",
    "tidytext = pd.read_csv(tidy_text_file, sep = '\\t')\n",
    "tidytext.loc[tidytext.sentiment == 'negative', 'sentiment'] = -1\n",
    "tidytext.loc[tidytext.sentiment == 'positive', 'sentiment'] = 1\n",
    "tidytext_nrc = tidytext[tidytext['lexicon']=='nrc']\n",
    "tidytext_bing = tidytext[tidytext['lexicon']=='bing']\n",
    "tidytext_loughran = tidytext[tidytext['lexicon']=='loughran']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Songs\n",
    "\n",
    "In this section, score the sentiment for all the songs for both artists in your data set. Score the sentiment by manually calculating the sentiment using the combined lexicons provided in this repository. \n",
    "\n",
    "After you have calculated these sentiments, answer the questions at the end of this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "\n",
    "# Adding the positive words to the dictionary\n",
    "for word in opinion_lexicon.positive():\n",
    "        word_dict[word] = pos_score\n",
    "        \n",
    "# Adding the negative words to the dictionary\n",
    "for word in opinion_lexicon.negative():\n",
    "        word_dict[word] = neg_score\n",
    "        \n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "    for word in bag_of_words:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score / len(bag_of_words)\n",
    "\n",
    "# cleaning function\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text(text):\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    text = [x for x in text if x not in sw]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)\n",
    "\n",
    "#Mod3 carry over functions\n",
    "def contains_emoji(s):\n",
    "    \n",
    "    s = str(s)\n",
    "    emojis = [ch for ch in s if is_emoji(ch)]\n",
    "\n",
    "    return(len(emojis) > 0)\n",
    "# Place any addtional functions or constants you need here. \n",
    "    \n",
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords - Function Above\n",
    "#sw = stopwords.words(\"english\")\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "# It's handy to have a full set of emojis\n",
    "all_language_emojis = set()\n",
    "\n",
    "for country in emoji.UNICODE_EMOJI : \n",
    "    for em in emoji.UNICODE_EMOJI[country] : \n",
    "        all_language_emojis.add(em)\n",
    "    \n",
    "def is_emoji(s):\n",
    "    return(s in all_language_emojis)\n",
    "\n",
    "def contains_emoji(s):\n",
    "    \n",
    "    s = str(s)\n",
    "    emojis = [ch for ch in s if is_emoji(ch)]\n",
    "\n",
    "    return(len(emojis) > 0)\n",
    "\n",
    "\n",
    "def remove_stop(tokens) :\n",
    "    # modify this function to remove stopwords\n",
    "    return(tokens)\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That \n",
    "        function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "    \n",
    "    # modify this function to return tokens\n",
    "    return(text)\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>bing_liu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Come And Stay With Me\"\\n</td>\n",
       "      <td>\\n \\n \\n I'll send away all my false pride\\n A...</td>\n",
       "      <td>i'll send away false pride\\n i'll forsake life...</td>\n",
       "      <td>0.044944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Pirate\"\\n</td>\n",
       "      <td>\\n \\n \\n He'll sail on with the summer wind\\n ...</td>\n",
       "      <td>he'll sail summer wind\\n blow day\\n everybody ...</td>\n",
       "      <td>0.072289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Stars\"\\n</td>\n",
       "      <td>\\n \\n \\n I was never one for saying what I rea...</td>\n",
       "      <td>never one say really feel\\n except tonight i'm...</td>\n",
       "      <td>-0.005780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"These Days\"\\n</td>\n",
       "      <td>\\n \\n \\n Well I've been out walking \\n And I d...</td>\n",
       "      <td>well i've walk much talk day day day seem thin...</td>\n",
       "      <td>0.011628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Love So High\"\\n</td>\n",
       "      <td>\\n \\n \\n Every morning I would wake up\\n And I...</td>\n",
       "      <td>every morning would wake up\\n i'd tie sun arou...</td>\n",
       "      <td>0.093750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                  song_name  \\\n",
       "0   cher  \"Come And Stay With Me\"\\n   \n",
       "1   cher                 \"Pirate\"\\n   \n",
       "2   cher                  \"Stars\"\\n   \n",
       "3   cher             \"These Days\"\\n   \n",
       "4   cher           \"Love So High\"\\n   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\n \\n \\n I'll send away all my false pride\\n A...   \n",
       "1  \\n \\n \\n He'll sail on with the summer wind\\n ...   \n",
       "2  \\n \\n \\n I was never one for saying what I rea...   \n",
       "3  \\n \\n \\n Well I've been out walking \\n And I d...   \n",
       "4  \\n \\n \\n Every morning I would wake up\\n And I...   \n",
       "\n",
       "                                          clean_text  bing_liu_score  \n",
       "0  i'll send away false pride\\n i'll forsake life...        0.044944  \n",
       "1  he'll sail summer wind\\n blow day\\n everybody ...        0.072289  \n",
       "2  never one say really feel\\n except tonight i'm...       -0.005780  \n",
       "3  well i've walk much talk day day day seem thin...        0.011628  \n",
       "4  every morning would wake up\\n i'd tie sun arou...        0.093750  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data['clean_text'] = lyrics_data['text'].apply(clean_text)\n",
    "lyrics_data = lyrics_data[lyrics_data['clean_text'].str.len() != 0]\n",
    "\n",
    "#BingLiu\n",
    "lyrics_data['bing_liu_score'] = lyrics_data['clean_text'].apply(bing_liu_score)\n",
    "lyrics_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>bing_liu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"My Love\"\\n</td>\n",
       "      <td>\\n \\n \\n When I go away\\n I know my heart can ...</td>\n",
       "      <td>go away\\n know heart stay love\\n understood\\n ...</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Move Me\"\\n</td>\n",
       "      <td>\\n \\n \\n Move me\\n Love the way you move me, b...</td>\n",
       "      <td>move me\\n love way move baby\\n groove me\\n lov...</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist    song_name                                               text  \\\n",
       "15    cher  \"My Love\"\\n  \\n \\n \\n When I go away\\n I know my heart can ...   \n",
       "137   cher  \"Move Me\"\\n  \\n \\n \\n Move me\\n Love the way you move me, b...   \n",
       "\n",
       "                                            clean_text  bing_liu_score  \n",
       "15   go away\\n know heart stay love\\n understood\\n ...        0.517241  \n",
       "137  move me\\n love way move baby\\n groove me\\n lov...        0.272727  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data[lyrics_data['artist']=='cher'].nlargest(n=2, columns = ['bing_liu_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>bing_liu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Cry Myself To Sleep\"\\n</td>\n",
       "      <td>\\n \\n \\n Every night, I lay my head\\n On my pi...</td>\n",
       "      <td>every night lay head\\n pillow bed\\n cry sleep\\...</td>\n",
       "      <td>-0.191176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Outrageous\"\\n</td>\n",
       "      <td>\\n \\n \\n Outrageous, outrageous\\n (They say) I...</td>\n",
       "      <td>outrageous outrageous\\n say i'm outrageous\\n r...</td>\n",
       "      <td>-0.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                song_name  \\\n",
       "240   cher  \"Cry Myself To Sleep\"\\n   \n",
       "158   cher           \"Outrageous\"\\n   \n",
       "\n",
       "                                                  text  \\\n",
       "240  \\n \\n \\n Every night, I lay my head\\n On my pi...   \n",
       "158  \\n \\n \\n Outrageous, outrageous\\n (They say) I...   \n",
       "\n",
       "                                            clean_text  bing_liu_score  \n",
       "240  every night lay head\\n pillow bed\\n cry sleep\\...       -0.191176  \n",
       "158  outrageous outrageous\\n say i'm outrageous\\n r...       -0.153846  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data[lyrics_data['artist']=='cher'].nsmallest(n=2, columns = ['bing_liu_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>bing_liu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Love Is Free\"\\n</td>\n",
       "      <td>\\n \\n \\n Free\\n Love is free, baby\\n Free\\n Lo...</td>\n",
       "      <td>free\\n love free baby\\n free\\n love free baby\\...</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Do You Really Want Me (Show Respect)\"\\n</td>\n",
       "      <td>\\n \\n \\n Boy listen to me careful now\\n Cause ...</td>\n",
       "      <td>boy listen careful now\\n cause something every...</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                                 song_name  \\\n",
       "337  robyn                          \"Love Is Free\"\\n   \n",
       "415  robyn  \"Do You Really Want Me (Show Respect)\"\\n   \n",
       "\n",
       "                                                  text  \\\n",
       "337  \\n \\n \\n Free\\n Love is free, baby\\n Free\\n Lo...   \n",
       "415  \\n \\n \\n Boy listen to me careful now\\n Cause ...   \n",
       "\n",
       "                                            clean_text  bing_liu_score  \n",
       "337  free\\n love free baby\\n free\\n love free baby\\...        0.307692  \n",
       "415  boy listen careful now\\n cause something every...        0.130435  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data[lyrics_data['artist']=='robyn'].nlargest(n=2, columns = ['bing_liu_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>bing_liu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Don't Fucking Tell Me What To Do\"\\n</td>\n",
       "      <td>\\n \\n \\n My drinking is killing me\\n My drinki...</td>\n",
       "      <td>drink kill me\\n drink kill me\\n drink kill me\\...</td>\n",
       "      <td>-0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Don't Fucking Tell Me What To Do\"\\n</td>\n",
       "      <td>\\n \\n \\n My drinking is killing me\\n My drinki...</td>\n",
       "      <td>drink kill me\\n drink kill me\\n drink kill me\\...</td>\n",
       "      <td>-0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Criminal Intent\"\\n</td>\n",
       "      <td>\\n \\n \\n Somebody alert the authorities, I got...</td>\n",
       "      <td>somebody alert authority get criminal intent\\n...</td>\n",
       "      <td>-0.184300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                             song_name  \\\n",
       "369  robyn  \"Don't Fucking Tell Me What To Do\"\\n   \n",
       "391  robyn  \"Don't Fucking Tell Me What To Do\"\\n   \n",
       "332  robyn                   \"Criminal Intent\"\\n   \n",
       "\n",
       "                                                  text  \\\n",
       "369  \\n \\n \\n My drinking is killing me\\n My drinki...   \n",
       "391  \\n \\n \\n My drinking is killing me\\n My drinki...   \n",
       "332  \\n \\n \\n Somebody alert the authorities, I got...   \n",
       "\n",
       "                                            clean_text  bing_liu_score  \n",
       "369  drink kill me\\n drink kill me\\n drink kill me\\...       -0.315789  \n",
       "391  drink kill me\\n drink kill me\\n drink kill me\\...       -0.315789  \n",
       "332  somebody alert authority get criminal intent\\n...       -0.184300  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data[lyrics_data['artist']=='robyn'].nsmallest(n=3, columns = ['bing_liu_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "Q: Overall, which artist has the higher average sentiment per song? \n",
    "\n",
    "A: Cher\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your first artist, what songs have the highest and lowest sentiments? Print those songs to the screen.\n",
    "\n",
    "A: Chers top two highest sentiment songs are My Love and Move me. Her lowest two are Cry myself to sleep and Outrageous.\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your second artist, what songs have the highest and lowest sentiments? Print those songs to the screen.\n",
    "\n",
    "A: Robyn Konichiwas highest two songs are Love is Free and Do you really want me. The lowest two for this artist are Don't F*cking tell me what to do and Criminal Intent.\n",
    "\n",
    "---\n",
    "\n",
    "Q: Plot the distributions of the sentiment scores for both artists. You can use `seaborn` to plot densities or plot histograms in matplotlib.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7a3e9f47c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "seaborn.histplot(data = lyrics_data[lyrics_data['artist']=='cher'], x = 'bing_liu_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7a3eb2c580>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEHCAYAAACp9y31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASDUlEQVR4nO3deZBlZX3G8e8DA0GBRAgjjuNMxj1SLqiNCxLLvYB/0LggZelYLmBcSuJSobQqMTFWNHE3iXFUIioaXCDiEhURpQyyNIrDUIOilsrIFDOuYLTUwV/+uGfKtqd7+k7PPfd29/v9VN2657z3nHt+7yxPn37vue9JVSFJascBky5AkjReBr8kNcbgl6TGGPyS1BiDX5Ias2rSBQzjqKOOqg0bNky6DElaVq6++uofVdXq2e3LIvg3bNjA9PT0pMuQpGUlyffnaneoR5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS3uxdt16kiz6sXbd+kl3QdrDspiyQZqUm7bdyKnvumzR+593xvEjrEYaDc/4JakxBr8kNcbgl6TG9Bb8SdYluSTJ1iTXJXlp1/6aJD9Mck33OLmvGiRJe+rzw91dwMur6mtJDgeuTnJR99pbquqNPR5bkjSP3oK/qrYD27vlW5NsBdb2dTxJ0nDGMsafZAPwQOCKrunFSTYnOTvJEfPsc3qS6STTO3fuHEeZktSE3oM/yWHAx4Ezq+oW4J3A3YFjGfxG8Ka59quqTVU1VVVTq1fvcctISdIi9Rr8SQ5iEPrnVtX5AFV1c1XdVlW/A94NPKTPGiRJf6jPq3oCvBfYWlVvntG+ZsZmTwK29FWDJGlPfV7V8wjgmcC1Sa7p2l4FnJbkWKCA7wFn9FiDJGmWPq/q+QqQOV76TF/HlCQtzG/uSlJjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL/XpgFUkWfRj7br1k+6BVqBVky5AWtF+t4tT33XZonc/74zjR1iMNOAZvyQ1xuCXpMb0FvxJ1iW5JMnWJNcleWnXfmSSi5Lc0D0f0VcNkqQ99XnGvwt4eVXdB3gY8KIkxwBnARdX1T2Bi7t1SdKY9Bb8VbW9qr7WLd8KbAXWAqcA53SbnQM8sa8aJEl7GssYf5INwAOBK4Cjq2o7DH44AHccRw2SpIHegz/JYcDHgTOr6pZ92O/0JNNJpnfu3NlfgZLUmF6DP8lBDEL/3Ko6v2u+Ocma7vU1wI659q2qTVU1VVVTq1ev7rNMSWpKn1f1BHgvsLWq3jzjpQuBjd3yRuATfdUgSdpTn9/cfQTwTODaJNd0ba8CXg98JMlzgR8AT+2xBknSLL0Ff1V9Bcg8Lz+2r+NKkvbOb+5KUmMMfklqjMEvSY0x+KWlzPn81QPn45eWMufzVw8845ekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktSY3oI/ydlJdiTZMqPtNUl+mOSa7nFyX8eXJM2tzzP+9wEnztH+lqo6tnt8psfjS5LmMFTwJ3nEMG0zVdWlwE8WWZckqSfDnvG/Y8i2Ybw4yeZuKOiI+TZKcnqS6STTO3fuXOShJEmzrdrbi0keDhwPrE7yshkv/TFw4CKO907gtUB1z28CnjPXhlW1CdgEMDU1VYs4liRpDnsNfuBg4LBuu8NntN8CPGVfD1ZVN+9eTvJu4FP7+h6SpP2z1+Cvqi8DX07yvqr6/v4eLMmaqtrerT4J2LK37SVJo7fQGf9uf5RkE7Bh5j5V9Zj5dkjyYeBRwFFJtgF/BzwqybEMhnq+B5yxqKolSYs2bPB/FPgP4D3AbcPsUFWnzdH83iGPJ0nqybDBv6uq3tlrJZKksRj2cs5PJnlhkjVJjtz96LUySVIvhj3j39g9v3JGWwF3G205kkbqgFUkWfTud77LOn544w9GWJCWgqGCv6ru2nchknrwu12c+q7LFr37eWccP8JitFQMFfxJnjVXe1W9f7TlSJL6NuxQz3Ezlg8BHgt8DTD4JWmZGXao5yUz15P8CfCBXiqSJPVqsdMy/xK45ygLkSSNx7Bj/J9kcBUPDCZnuw/wkb6KkiT1Z9gx/jfOWN4FfL+qtvVQjySpZ0MN9XSTtV3PYIbOI4Df9FmUJKk/w96B62nAlcBTgacBVyTZ52mZJUmTN+xQz6uB46pqB0CS1cAXgI/1VZgkqR/DXtVzwO7Q7/x4H/aVJC0hw57xfzbJ54APd+unAp/ppyRJUp8WuufuPYCjq+qVSf4SOAEI8FXg3DHUJ0kasYWGa94K3ApQVedX1cuq6q8ZnO2/te/iJEmjt1Dwb6iqzbMbq2qawW0YJUnLzELBf8heXrvdKAuRJI3HQsF/VZLnz25M8lzg6n5KkiT1aaGres4ELkjyDH4f9FPAwcCT+ixMktSPvQZ/Vd0MHJ/k0cB9u+ZPV9UXe69MktSLYefjvwS4pOdaJElj4LdvJakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY3pLfiTnJ1kR5ItM9qOTHJRkhu65yP6Or4kaW59nvG/DzhxVttZwMVVdU/g4m5dkjRGvQV/VV0K/GRW8ynAOd3yOcAT+zq+JGlu4x7jP7qqtgN0z3ecb8MkpyeZTjK9c+fOsRUoSSvdkv1wt6o2VdVUVU2tXr160uVI0oox7uC/OckagO55x5iPL0nNG3fwXwhs7JY3Ap8Y8/ElqXl9Xs75YeCrwL2TbOtu1/h64PFJbgAe361LksZoqBuxLEZVnTbPS4/t65iSpIUt2Q93JUn9MPglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGv5a0tevWk2TRj1UHH7Jf+0sr0apJFyDtzU3bbuTUd1226P3PO+P4/d5fWmk845ekxhj8ktQYg1+SGjORMf4k3wNuBW4DdlXV1CTqkKQWTfLD3UdX1Y8meHxJapJDPZLUmEkFfwGfT3J1ktPn2iDJ6Ummk0zv3LlzzOVJ0so1qeB/RFU9CDgJeFGSR87eoKo2VdVUVU2tXr16/BVK0go1keCvqpu65x3ABcBDJlGHJLVo7MGf5NAkh+9eBp4AbBl3HZLUqklc1XM0cEE3D8oq4ENV9dkJ1CFJTRp78FfVd4EHjPu4kqQBL+eUpMYY/JLUGINf0vwOWLVf9zNYu279pHugOTgfv6T5/W6X9zNYgTzjl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+NWrtevW79d14JJGz+v41aubtt3odeDSEuMZvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWrMig/+/b2O3PnEJa00K/46fq8jl6Q/tOLP+CVJf8jgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMG/wu3v9xhWHXyI8+lL+2EpfpdoxV/H37pRfI/B70FIi7cUv0vkGb8kNcbgl6TGGPyS1JiJBH+SE5N8M8m3k5w1iRokqVVjD/4kBwL/BpwEHAOcluSYcdchSa2axBn/Q4BvV9V3q+o3wH8Bp0ygDklqUqpqvAdMngKcWFXP69afCTy0ql48a7vTgdO71XsD3+yppKOAH/X03uNiHyZvudcP9mGpGGUf/qyqVs9unMR1/HN9q2ePnz5VtQnY1HsxyXRVTfV9nD7Zh8lb7vWDfVgqxtGHSQz1bAPWzVi/C3DTBOqQpCZNIvivAu6Z5K5JDgaeDlw4gTokqUljH+qpql1JXgx8DjgQOLuqrht3HTP0Ppw0BvZh8pZ7/WAflor+h7jH/eGuJGmy/OauJDXG4JekxjQX/EmOTHJRkhu65yPm2OaQJFcm+UaS65L8/SRqnc+QfViX5JIkW7s+vHQStc5lmPq77c5OsiPJlnHXOJ+FphvJwNu71zcnedAk6tybIfrw50m+muTXSV4xiRoXMkQfntH9+W9OclmSB0yizvkMUf8pXe3XJJlOcsJIC6iqph7APwNndctnAW+YY5sAh3XLBwFXAA+bdO372Ic1wIO65cOBbwHHTLr2YevvXnsk8CBgy6Rr7uo5EPgOcDfgYOAbs/9MgZOB/+n+DT0MuGLSdS+iD3cEjgNeB7xi0jUvsg/HA0d0yyctpb+HIes/jN9/Bnt/4PpR1tDcGT+D6SHO6ZbPAZ44e4Ma+EW3elD3WEqfgg/Th+1V9bVu+VZgK7B2bBXu3YL1A1TVpcBPxlXUEIaZbuQU4P3dv6HLgTskWTPuQvdiwT5U1Y6qugr47SQKHMIwfbisqn7arV7O4PtCS8Uw9f+iutQHDmXE+dNi8B9dVdthEI4Mzm72kOTAJNcAO4CLquqKMda4kKH6sFuSDcADGfzmshTsU/1LyFrgxhnr29jzh+kw20zSUq9vGPvah+cy+C1sqRiq/iRPSnI98GngOaMsYEXeejHJF4A7zfHSq4d9j6q6DTg2yR2AC5Lct6rGNtY8ij5073MY8HHgzKq6ZRS1DXnckdS/xAwz3chQU5JM0FKvbxhD9yHJoxkE/2jHyPfPsNPWXMAgex4JvBZ43KgKWJHBX1Xz/gEluTnJmqra3v0KvmOB9/pZki8BJwJjC/5R9CHJQQxC/9yqOr+nUuc0yr+DJWSY6UaW+pQkS72+YQzVhyT3B94DnFRVPx5TbcPYp7+Dqro0yd2THFVVI5m8rcWhnguBjd3yRuATszdIsro70yfJ7Rj8pL1+bBUubJg+BHgvsLWq3jzG2oaxYP1L1DDTjVwIPKu7uudhwM93D2stESthypQF+5BkPXA+8Myq+tYEatybYeq/R/d/mO7KsIOB0f3wmvQn3ON+AH8KXAzc0D0f2bXfGfhM/f5T9K8Dmxmc5f/tpOteRB9OYPDr42bgmu5x8qRrH7b+bv3DwHYGHzJuA567BGo/mcEVUt8BXt21vQB4QbccBjca+g5wLTA16ZoX0Yc7dX/etwA/65b/eNJ172Mf3gP8dMa//elJ17yP9f8NcF1X+1eBE0Z5fKdskKTGtDjUI0lNM/glqTEGvyQ1xuCXpMYY/JLUGINfkhpj8GtZSrJhrumak7wnyTF9HCfJVJK3j+q9pUlZkVM2qF1V9bwe33samO7r/YeVZFVV7Zp0HVq+POPXcrYqyTndDSs+luT2Sb6UZAogyS+SvC6DG+pcnuTorv3u3fpVSf4hyS/2fpiBJI9K8qlu+TUzb1KSZEs3C+pc+x2a5NNdHVuSnNq1H9fdJOQbGdz45/AMbgL0n0muTfL1bpIxkjw7yUeTfBL4fPeeZ3d9+HqS2dNDS/My+LWc3RvYVFX3ZzC9wAtnvX4ocHlVPQC4FHh+1/424G1VdRzjmaDsROCmqnpAVd0X+Gw3R8t5wEu7+h4H/Ap4EUBV3Q84DTgnySHd+zwc2FhVj2Ewy+kXuz48GviXJIeOoS9aAQx+LWc3VtX/dssfZM+pd38DfKpbvhrY0C0/HPhot/yhPgvsXAs8LskbkvxFVf2cwQ+t7TW44QlVdUs3fHMC8IGu7Xrg+8C9uve5qKp235jmCcBZ3T0jvgQcAqwfQ1+0AjjGr+Vs9kRTs9d/W7+fjOo2RvvvfRd/eOJ0yHwbVtW3kjyYwcRc/5Tk88B/z1EvzD1X+27/N2u7J1fVN4cvWRrwjF/L2fokD++WTwO+MuR+lwNP7pafvshjf4/B/YB3T5t71/k2THJn4JdV9UHgjd1+1wN3TnJct83hSVYxGJJ6Rtd2LwZn8XOF++eAl8yYuveBi+yHGmTwaznbCmxMshk4EnjnkPudCbwsyZUMbkr/80Uc++PAkd1Qy18xmGJ3PvcDruy2fTXwjzW41+qpwDuSfAO4iMFvDf8OHJjkWgafATy7qn49x3u+lsG9oDd3l5u+dhF9UKOcllnNSXJ74FdVVUmeDpxWVV4Vo2Y4xq8WPRj4126Y5GeM+EbW0lLnGb8EJLkf3dU0M/y6qh66D++x+85isz22ltY9X9U4g1+SGuOHu5LUGINfkhpj8EtSYwx+SWrM/wMvUwT6sNUDTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.histplot(data = lyrics_data[lyrics_data['artist']=='robyn'], x = 'bing_liu_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Twitter Descriptions\n",
    "\n",
    "In this section, define two sets of emojis you designate as positive and negative. Make sure to have at least 10 emojis per set. You can learn about the most popular emojis on Twitter at [the emojitracker](https://emojitracker.com/). \n",
    "\n",
    "Associate your positive emojis with a score of +1, negative with -1. Score the average sentiment of your two artists based on the Twitter descriptions of their followers. The average sentiment can just be the total score divided by number of followers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return re.findall(r'[\\w-]*\\p{L}[\\w-]*', text)\n",
    "\n",
    "\n",
    "def remove_punctuation(text, exceptions=None):\n",
    "    all_but = [\n",
    "        r'\\w',\n",
    "        r'\\s']\n",
    "        #text (str): The text to remove punctuation from.\n",
    "        #exceptions (list): List of symbols to keep in the given text.\n",
    "    \n",
    "    if exceptions is not None:\n",
    "        all_but.extend(exceptions)\n",
    "\n",
    "    pattern = '[^{}]'.format(''.join(all_but))\n",
    "\n",
    "    return re.sub(pattern, '', text) \n",
    "\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    def remove_stop(tokens):\n",
    "        return [t for t in tokens if t.lower() not in stopwords]\n",
    "\n",
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]\n",
    "\n",
    "def prepare(text, pipeline): \n",
    "    token = text\n",
    "    for transform in pipeline: \n",
    "        token = transform(token)\n",
    "        return token\n",
    "\n",
    "#Convert dataframes to string\n",
    "lyrics_data['lyrics'] = lyrics_data['text'].map(str)\n",
    "twitter_data['description'] = twitter_data['description'].map(str)\n",
    "\n",
    "#Apply pipeline\n",
    "lyrics_data['tokens'] = lyrics_data['lyrics'].apply(prepare, pipeline= my_pipeline)\n",
    "\n",
    "lyrics_data[\"tokens\"] = lyrics_data[\"text\"].apply(prepare,pipeline=my_pipeline)\n",
    "lyrics_data[\"num_tokens\"] = lyrics_data[\"tokens\"].map(len) \n",
    "\n",
    "twitter_data[\"tokens\"] = twitter_data[\"description\"].apply(prepare,pipeline=my_pipeline)\n",
    "twitter_data[\"num_tokens\"] = twitter_data[\"tokens\"].map(len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['has_emoji'] = twitter_data[\"description\"].apply(contains_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['tokens'] = twitter_data['description'].map(word_tokenize)\n",
    "lyrics_data['tokens'] = lyrics_data['tokens'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>description</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>472114</th>\n",
       "      <td>cher</td>\n",
       "      <td>bi Trust nun 😒💣 Just a youngin living life to ...</td>\n",
       "      <td>[bi, Trust, nun, 😒💣, Just, a, youngin, living,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862148</th>\n",
       "      <td>cher</td>\n",
       "      <td>🍬 (last account got deleted big sad)</td>\n",
       "      <td>[🍬, (, last, account, got, deleted, big, sad, )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756038</th>\n",
       "      <td>cher</td>\n",
       "      <td>#VoteThemOut #TakeAKnee #AntiRacist #Resistanc...</td>\n",
       "      <td>[#, VoteThemOut, #, TakeAKnee, #, AntiRacist, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist                                        description  \\\n",
       "472114   cher  bi Trust nun 😒💣 Just a youngin living life to ...   \n",
       "862148   cher               🍬 (last account got deleted big sad)   \n",
       "756038   cher  #VoteThemOut #TakeAKnee #AntiRacist #Resistanc...   \n",
       "\n",
       "                                                   tokens  \n",
       "472114  [bi, Trust, nun, 😒💣, Just, a, youngin, living,...  \n",
       "862148   [🍬, (, last, account, got, deleted, big, sad, )]  \n",
       "756038  [#, VoteThemOut, #, TakeAKnee, #, AntiRacist, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follower_emoji = twitter_data[twitter_data.has_emoji].sample(10)[[\"artist\",\"description\",\"tokens\"]]\n",
    "follower_emoji.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_summary = adv.extract_emoji(follower_emoji)\n",
    "follower_emoji = emoji_summary['emoji_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What is the average sentiment of your two artists? \n",
    "\n",
    "A: <!-- Your answer here --> \n",
    "\n",
    "---\n",
    "\n",
    "Q: Which positive emoji is the most popular for each artist? Which negative emoji? \n",
    "\n",
    "A: <!-- Your answer here --> \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
